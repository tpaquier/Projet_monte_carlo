{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42432d8d-94f8-4932-ad13-1ee5ac96d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importation des packages\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eb6d17-48d2-4823-bf3b-a9f70dd4d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(n, alpha=2, beta=0, gamma=1, delta=0):\n",
    "    # Initialize samples array with zeros\n",
    "    sample = np.zeros(n)\n",
    "    \n",
    "    # Constants that do not depend on the sample index and thus can be computed once\n",
    "    if alpha != 1:\n",
    "        S_alpha_beta = (1 + beta ** 2 * np.tan(np.pi * alpha / 2) ** 2) ** (1 / (2 * alpha))\n",
    "        B_alpha_beta = (1 / alpha) * np.arctan(beta * np.tan(np.pi * alpha / 2))\n",
    "\n",
    "    for i in range(n):\n",
    "        U = np.random.uniform(-np.pi/2, np.pi/2)\n",
    "        W = -np.log(1 - np.random.uniform(0,1))\n",
    "        \n",
    "        # Handle the case alpha = 1 separately\n",
    "        if alpha != 1:\n",
    "            part1 = np.sin(alpha * (U + B_alpha_beta)) / (np.cos(U) ** (1 / alpha))\n",
    "            part2 = (np.cos(U - alpha * (U + B_alpha_beta)) / W) ** ((1 - alpha) / alpha)\n",
    "            sample[i] = S_alpha_beta * part1 * part2\n",
    "        else:\n",
    "            sample[i] = (2 / np.pi) * ((np.pi / 2 + beta * U) * np.tan(U) - beta * np.log((np.pi / 2 * W * np.cos(U))/(np.pi+beta*U)))\n",
    "\n",
    "    # Apply scaling and location shifting\n",
    "    sample = gamma * sample + delta\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5940a546-e114-42a1-8814-9ad9de70e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_fun_zolo(t, nu, etha, tau):\n",
    "    \"\"\"characteristic function to use from S2 to S5\n",
    "\n",
    "    Parameters\n",
    "    ----------------------------\n",
    "    t : float\n",
    "    the \"instant\" we want to check\n",
    "\n",
    "    nu : float\n",
    "    parameter of the alpha-stable distribution, >= 1/4.\n",
    "\n",
    "    etha :float\n",
    "    parameter of the alpha-stable distribution, np.sign(etha) <= min(1, 2*np.sqrt(nu)-1)\n",
    "\n",
    "    tau : float\n",
    "    parameter of the alpha-stable distribution, absolute value < inf\n",
    "    ------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    y = -np.exp((nu**(-1/2))*(np.log(np.abs(t)) + tau - 1j*(np.pi/2)*etha*np.sign(t)) + np.e*((nu**(-1/2))-1))\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b145898-5a27-461a-8238-d4b29efe0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emp_char_fun(sample, t):\n",
    "    \"\"\"function to evaluate the empirical characteristic of a function at an instant t\n",
    "\n",
    "    Parameters\n",
    "    -------------------------\n",
    "    sample : array-like\n",
    "    sample on which we want to evaluate the characteristic function\n",
    "\n",
    "    t : int, float\n",
    "    moment to estimate/generate\n",
    "    --------------------------\n",
    "    \"\"\"\n",
    "    expo_transfo = np.exp(-sample*1j*t)\n",
    "    empirical = np.mean(expo_transfo)\n",
    "    return empirical\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730672f9-d2bb-4caf-9f57-df2d110eb6ce",
   "metadata": {},
   "source": [
    "$\\theta = (\\alpha, \\beta, \\gamma, \\delta)$ \n",
    "\n",
    "N = 1000\n",
    "\n",
    "$x^1,...,x^p$ ~ $\\pi(x|\\theta)$\n",
    "\n",
    "$\\pi_{LF}(\\theta|y)$ = $\\pi(\\theta)\\mathbb{E}_{\\pi(x|\\theta)}[K_{\\epsilon} (y-x)]$ $\\leftarrow$ we do monte carlo on this\n",
    "\n",
    "$K_{\\epsilon} (y-x)$ def by $S(y)$ ~ $N(S(x), \\epsilon^2 \\hat{\\Sigma})$ $\\leftarrow$ that would be our gaussian kernel\n",
    "\n",
    "$\\hat{\\Sigma}$ is an estimate of $Cov(S(x)\\hat{\\theta})$\n",
    "\n",
    "$\\Lambda$ = diag(0.25, 0.25, 1, 1)\n",
    "\n",
    "Mutation kernel : $M_t(\\theta_t) = \\sum_{i=1}^{N} W_{t-1}^{(i)}(\\theta_{t-1}^{(i)}) \\phi(\\theta_t ; \\theta_{t-1}^{(i)})$\n",
    "\n",
    "Gaussian kernel : $L(x,t) = \\sum_{n = -M}^{M}f(x-n)G(n,t)$\n",
    "\n",
    "with G(n,t) = $\\frac{1}{\\sqrt{2\\pi t}}e^{-\\frac{n^2}{2t}}$\n",
    "\n",
    "\n",
    "As t increases, $\\epsilon_t$ decreases\n",
    "\n",
    "$\\hat{c_t}$ is the 90th quantile of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f529b7-84ae-4520-a477-7f3b501f2cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a73037-8b81-4e2b-a980-8c7bd8ef51da",
   "metadata": {},
   "source": [
    "# Seed : 256652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9875ffab-8c7a-495b-9957-ebf7045df588",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(256652)\n",
    "\n",
    "#creation des prior des parametres cf section 3.1\n",
    "\n",
    "prior_alpha = np.random.uniform(1.1, 2., size=1000)\n",
    "prior_beta = np.random.uniform(-1., 1, size=1000)\n",
    "prior_gamma = np.random.uniform(0., 300., size=1000)\n",
    "prior_delta = np.random.uniform(-300., 300., size=1000)\n",
    "\n",
    "#scale parameters\n",
    "\n",
    "#epsilon_t\n",
    "\n",
    "mille = np.linspace(start=100, stop=1000, endpoint=True, num=10)[::-1]\n",
    "cent = np.linspace(start=10, stop=100, endpoint=False, num=90)[::-1]\n",
    "dix = np.linspace(start=5, stop=10, endpoint=False, num=10)[::-1]\n",
    "cinq = np.linspace(start=3, stop=5, endpoint=False, num=40)[::-1]\n",
    "trois = np.linspace(start=0, stop=3, endpoint=False, num=300)[::-1]\n",
    "\n",
    "scale_param = np.concatenate((mille, cent, dix, cinq, trois))\n",
    "\n",
    "\n",
    "N = 1000\n",
    "varcov_lambda = np.array([0.25,0.,0.,0.,0.,0.25, 0., 0.,0.,0.,1.,0.,0.,0.,0.,1]).reshape([4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197d552a-032b-40de-bc62-bce8ffba6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_ker(u=0, y=0):\n",
    "    \"\"\"gaussian kernel for weights\n",
    "    \n",
    "    Parameters\n",
    "    -------------------\n",
    "    y : float\n",
    "    the point we have, the output\n",
    "\n",
    "    u : float\n",
    "    the point from which we want to calculate a weight\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    w = (1/np.sqrt(2*np.pi))*np.exp(-(u-y)**2/2)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db592d0c-7973-4679-a563-5911dc162a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_culloch_q(data, gamma=1):\n",
    "    \"\"\"fonction pour calculer les quantiles de mc_culloch utilises dans le papier\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    data : array\n",
    "    les donnes pour lesquelles on veut calculer les quantiles\n",
    "\n",
    "    gamma : float\n",
    "    valeur 1 par defaut, d'apres le papier, on utilise le gamma utilise pour faire les simulations\n",
    "    ----------------\n",
    "    \"\"\"\n",
    "    data_sorted = np.sort(data)\n",
    "    useful_quantiles = np.quantile(a=data_sorted, q=[0.95, 0.75, 0.5, 0.25, 0.05])\n",
    "    q_95 = useful_quantiles[0]\n",
    "    q_75 = useful_quantiles[1]\n",
    "    q_50 = useful_quantiles[2]\n",
    "    q_25 = useful_quantiles[3]\n",
    "    q_05 = useful_quantiles[4]\n",
    "    alpha_hat = (q_95-q_05)/(q_75-q_25)\n",
    "    beta_hat = (q_95+q_05+2*q_50)/(q_95-q_05)\n",
    "    gamma_hat = (q_75-q_25)/gamma\n",
    "    #on a le gamma au denominateur parce que c'est comme ca qu on a genere nos donnees\n",
    "    #d'apres le papier, ca va de prendre le gamma qu'on a utililse pour generer\n",
    "    delta_hat = np.mean(data_simulation)\n",
    "    S_1 = np.transpose(np.array((alpha_hat, beta_hat, gamma_hat, delta_hat)))\n",
    "    return S_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd6477b-e5e3-4eea-ac12-b7d74e0ad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zolotarev_transfo(sample, xi):\n",
    "    \"\"\"function to use for the estimation based on the zolotarev transformation\n",
    "\n",
    "    Parameters\n",
    "    --------------------------\n",
    "    Sample : array-like\n",
    "    Sample to do the transformation on\n",
    "\n",
    "    xi : int, float\n",
    "    The constant used in the transformation\n",
    "    --------------------------\n",
    "    \"\"\"\n",
    "    if xi<=0 or xi>1/2 :\n",
    "        raise ValueError('Xi must be between 0 and 1/2')\n",
    "    taille = len(sample)\n",
    "    Z = []\n",
    "    for i in range(int(taille/3)):\n",
    "        transfo = sample[3*i-2] - xi*sample[3*i-1] - (1 - xi)*sample[3*i]\n",
    "        Z.append(transfo)\n",
    "    V = []\n",
    "    U = []\n",
    "    for i in range(len(Z)):\n",
    "        V.append(np.log(np.abs(Z[i])))\n",
    "        U.append(np.sign(sample[i]))\n",
    "    V = np.array(V)\n",
    "    U = np.array(U)\n",
    "    S_U_squared = (np.std(U))**2\n",
    "    S_V_squared = (np.std(V))**2\n",
    "    nu_tilde = (6/(np.pi)**2)*S_V_squared - (3/2)*S_U_squared + 1\n",
    "    etha_hat = np.mean(U)\n",
    "    tau_hat = np.mean(V)\n",
    "    nu_hat = 0\n",
    "    if nu_tilde > ((1+np.abs(etha_hat))**2)/4:\n",
    "        nu_hat = nu_tilde\n",
    "    else:\n",
    "        nu_hat = ((1+np.abs(etha_hat))**2)/4\n",
    "    delta_hat = np.mean(sample)\n",
    "    S_2 = np.array((nu_hat, etha_hat, tau_hat, delta_hat))\n",
    "    return S_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1aa10299-975a-4d2f-a0f0-3a0616c4aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_hat(x, t):\n",
    "    \"\"\"function to use to calculate presss moments\n",
    "\n",
    "    Parameters\n",
    "    ---------------\n",
    "    x : array-like\n",
    "\n",
    "    the data\n",
    "\n",
    "    t : int, float\n",
    "    the real number we want to know the image by the function\n",
    "    ---------------\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.arctan(np.sum(np.cos(t*x))/np.sum(np.sin(t*x)))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f405de-b267-4719-a715-f536c2575e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def presss_moments(sample, t_1=0.2, t_2=0.8, t_3=0.1, t_4=0.4):\n",
    "    \"\"\"function to calculate press's moments\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "\n",
    "    sample : array-like\n",
    "\n",
    "    the data\n",
    "\n",
    "    t_1 : int, float\n",
    "    t_2 : int, float\n",
    "    t_3 : int, float\n",
    "    t_4 : int, float\n",
    "    moments we want to evaluate, the default parameters are given by Koutrouvelis (1980)\n",
    "    ---------------\n",
    "    \"\"\"\n",
    "    \n",
    "    #estimation of characteristic function at different moments\n",
    "    transfo_1 = emp_char_fun(sample, t=t_1)\n",
    "    transfo_2 = emp_char_fun(sample, t=t_2)\n",
    "    transfo_3 = emp_char_fun(sample, t=t_3)\n",
    "    transfo_4 = emp_char_fun(sample, t=t_4)\n",
    "    log_gamma_hat_top = (np.log(np.abs(t_1))*np.log(-np.log(np.abs(transfo_2)))-np.log(np.abs(t_2))*np.log(-np.log(np.abs(transfo_1))))\n",
    "    log_gamma_hat = log_gamma_hat_top/np.log(np.abs(t_1/t_2))\n",
    "    alpha_hat = np.log(np.log(np.abs(transfo_1))/np.log(np.abs(transfo_2)))/np.log(np.abs(t_1/t_2))\n",
    "    beta_hat_top = ((u_hat(x=sample, t=t_4)/t_4)-(u_hat(x=sample, t=t_3)/t_3))\n",
    "    beta_hat_bot = ((np.abs(t_4)**(alpha_hat-1))-(np.abs(t_3)**(alpha_hat-1)))*(np.exp(log_gamma_hat)**alpha_hat)*np.tan((alpha_hat*np.pi)/2)\n",
    "    beta_hat = beta_hat_top/beta_hat_bot\n",
    "    delta_hat_top = np.abs(t_4)**(alpha_hat-1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81928318-b2a1-4edd-96e1-83057503809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.01087811 -0.00261003  0.68613717  0.10877838]\n"
     ]
    }
   ],
   "source": [
    "test = generation(n=100000, alpha=1, beta=0, gamma=1, delta=0)\n",
    "S_hat = zolotarev_transfo(test, xi=0.15)\n",
    "print(S_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3a3553b-3687-4f45-a6f0-66c5e31713c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ca converge tres tres lentement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d3973d-8603-4866-8fc0-1294941a1e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#data generation and definition of moments\n",
    "\n",
    "data_simulation = generation(n=1000, alpha=2, beta=0.5, gamma=3, delta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ce4e91-59ca-4e43-99dd-95d22c873514",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#sort data to be sure the quantiles are well computed bc you never know\n",
    "data_simulation = np.sort(data_simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd10c032-a553-4afd-b655-2eb87e9fab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_quantiles = np.quantile(a=data_simulation, q=[0.95, 0.75, 0.5, 0.25, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6852eb6-8494-4071-9d6e-3673fbec722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.11176007,  6.94655623,  4.21829831,  1.29888314, -2.85161126])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c302b652-f478-4e7f-8f5e-8806bbbad5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_95 = useful_quantiles[0]\n",
    "q_75 = useful_quantiles[1]\n",
    "q_50 = useful_quantiles[2]\n",
    "q_25 = useful_quantiles[3]\n",
    "q_05 = useful_quantiles[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc184de7-a21a-4e69-9511-1e1c623632d6",
   "metadata": {},
   "source": [
    "### Mc Culloch's quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71aefc4e-7b67-4ab3-b5f1-b9f74fc0fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_hat = (q_95-q_05)/(q_75-q_25)\n",
    "beta_hat = (q_95+q_05+2*q_50)/(q_95-q_05)\n",
    "gamma_hat = (q_75-q_25)/3\n",
    "#on a le 3 au denominateur parce que c'est comme ca qu on a genere nos donnees\n",
    "#d'apres le papier, ca va de prendre le gamma qu'on a utililse pour generer\n",
    "delta_hat = np.mean(data_simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46ea9d73-6242-4cbc-9abe-4b9eaff06a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1 = np.transpose(np.array((alpha_hat, beta_hat, gamma_hat, delta_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1b82c58-ed99-47f6-8d34-274f9fc45ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4724114 , 1.19575316, 1.8825577 , 4.1165704 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "364a9b69-f54d-4383-956f-a4b94025e4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.11657039995988"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e14302-6542-4195-8937-bda53ef5b4fb",
   "metadata": {},
   "source": [
    "Test runned with one million simulations, the estimators seemed to be biased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d674f-ec0b-4bc5-b957-baf7044dceeb",
   "metadata": {},
   "source": [
    "def prior_lf_mc():\n",
    "    \"estimation monte carlo de la vraisemblance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b85d15-7401-4cb5-8047-6e0d3385de77",
   "metadata": {},
   "source": [
    "def smc_prc_abc(N=1000, epsilon_t):\n",
    "    \"\"\"Algorithme ABC de l'appendix A de l'article.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ---------------------------\n",
    "    N : int\n",
    "    Nombre d'echantillons crees pour les parametres\n",
    "\n",
    "    epsilon_t : array\n",
    "    Les marges d'acceptation pour l'algorithme\n",
    "    \"\"\"\n",
    "    #les prior sont des uniformes cf partie 3.1\n",
    "    prior_alpha = np.random.uniform(1.1, 2., size=N)\n",
    "    prior_beta = np.random.uniform(-1., 1, size=N)\n",
    "    prior_gamma = np.random.uniform(0., 300., size=N)\n",
    "    prior_delta = np.random.uniform(-300., 300., size=N)\n",
    "    prior_gen = np.vstack((prior_alpha,prior_beta,prior_delta, prior_gamma))\n",
    "    \n",
    "    #the weights\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdd2fdae-a55a-4d9d-abd9-f0783c636817",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array((1,2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "247416ed-cc2c-4b90-972b-3ce5697cdea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20105695-c735-4530-b130-1f22ecf7fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array((5,4,3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a82e8a7-7712-4a15-bb1e-99e94ed16f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.5, 1. , 2. , 5. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01481a25-6ea7-4cfd-a8f9-08449ebfc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array((5,1,3,2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "185e4219-6e92-456f-871d-fd047fddf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.vstack((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1453d515-47b0-4811-8e18-04d363f980ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [5, 4, 3, 2, 1],\n",
       "       [5, 1, 3, 2, 4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "989a6737-135e-4e1b-b90e-6dcbcfdf5eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.324555320336759"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9407416-a8ea-4c87-ac03-b1f43190feda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1973be9-93d3-436e-81dd-c9c0ba7b6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_reject_abc(N=1000, epsilon_t=0.5, alpha=2, beta=0, gamma=1, delta=0):\n",
    "    \"\"\"algorithme d'acceptation rejet 'basique', vu en cours\n",
    "\n",
    "    Parameters\n",
    "    ---------------------------------\n",
    "    N : int\n",
    "    nombre de simulations faites\n",
    "\n",
    "    epsilon_t : array\n",
    "    scale parameters, marge d'acceptation\n",
    "\n",
    "    alpha, beta, gamma, delta :\n",
    "    parametres pour les simulations\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    data = generation(n=N, alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "    #priors\n",
    "    prior_alpha = np.random.uniform(1.1, 2., size=5*N)\n",
    "    prior_beta = np.random.uniform(-1., 1, size=5*N)\n",
    "    prior_gamma = np.random.uniform(0., 300., size=5*N)\n",
    "    prior_delta = np.random.uniform(-300., 300., size=5*N)\n",
    "    prior_gen = np.vstack((prior_alpha,prior_beta,prior_delta, prior_gamma))\n",
    "    true_data_estim = zolotarev_transfo(sample=data, xi=0.15)\n",
    "    bon_param = np.array(())\n",
    "    alpha_test = 0\n",
    "    beta_test = 0\n",
    "    gamma_test = 0\n",
    "    delta_test = 0\n",
    "    for i in range(5*N):\n",
    "        proposed_data = generation(n=N, alpha=prior_gen[:,i][0],\n",
    "                                   beta=prior_gen[:,i][1],\n",
    "                                   delta=prior_gen[:,i][2],\n",
    "                                   gamma=prior_gen[:,i][3])\n",
    "        alpha_test = prior_gen[:,i][0]\n",
    "        beta_test = prior_gen[:,i][1]\n",
    "        gamma_test = prior_gen[:,i][2]\n",
    "        delta_test = prior_gen[:,i][3]\n",
    "        estimated = mc_culloch_q(proposed_data, gamma=prior_gen[:,i][3])\n",
    "        weights = gaussian_ker(estimated -true_data_estim)\n",
    "        if np.linalg.norm(estimated-true_data_estim) < epsilon_t:\n",
    "            return alpha_test, beta_test, gamma_test, delta_test\n",
    "        else :\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dfa5ee0-f0cd-4573-a61d-89e13c597667",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = accept_reject_abc(N=200, epsilon_t=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24742030-7f09-4855-918a-c804701299c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 4.172325134277344e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_1\n",
    "end = time.time()\n",
    "print(test_1, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7d257a8-18ec-4763-8dc9-2f29ff30391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avec une si petite distance ca ne marchait pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37ebece8-6b21-4bce-94be-0c404f6bfa7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387.079820394516\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "liste_parametres = []\n",
    "for i in range(len(scale_param)):\n",
    "    pouet = accept_reject_abc(N=200, epsilon_t=scale_param[-i], alpha=1, beta=0, gamma=1, delta=0)\n",
    "    intermediaire = [scale_param[-i], pouet]\n",
    "    liste_parametres.append(intermediaire)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9e6db6a-f296-42a7-8257-a6415823e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#must change the parameters, N must be 200, too long otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0c1dfe2-c3a1-47d3-99dc-74e293e713f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "liste_parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "953a19d0-b5ed-401a-bea8-c2f3335819ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not working very well, new distance needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9a6f8ea-8e3b-446b-a198-74f37928df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works probably, pb : wrong use of mc culloch quantiles, need to invert --> pb , how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570db26-af35-41e2-bebf-39b8e6d1f529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
