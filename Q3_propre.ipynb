{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a52481-35e9-4450-b433-157f1c2abe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969165d9-71ec-4313-90cd-8aff6329a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(n, alpha=1.7, beta=0.9, gamma=10, delta=10):\n",
    "    # Initialize samples array with zeros\n",
    "    sample = np.zeros(n)\n",
    "    \n",
    "    # Constants that do not depend on the sample index and thus can be computed once\n",
    "    if alpha != 1:\n",
    "        S_alpha_beta = (1 + beta ** 2 * np.tan(np.pi * alpha / 2) ** 2) ** (1 / (2 * alpha))\n",
    "        B_alpha_beta = (1 / alpha) * np.arctan(beta * np.tan(np.pi * alpha / 2))\n",
    "\n",
    "    for i in range(n):\n",
    "        U = np.random.uniform(-np.pi/2, np.pi/2)\n",
    "        W = -np.log(1 - np.random.uniform(0,1))\n",
    "        \n",
    "        # Handle the case alpha = 1 separately\n",
    "        if alpha != 1:\n",
    "            part1 = np.sin(alpha * (U + B_alpha_beta)) / (np.cos(U) ** (1 / alpha))\n",
    "            part2 = (np.cos(U - alpha * (U + B_alpha_beta)) / W) ** ((1 - alpha) / alpha)\n",
    "            sample[i] = S_alpha_beta * part1 * part2\n",
    "        else:\n",
    "            sample[i] = (2 / np.pi) * ((np.pi / 2 + beta * U) * np.tan(U) - beta * np.log((np.pi / 2 * W * np.cos(U))/(np.pi+beta*U)))\n",
    "\n",
    "    # Apply scaling and location shifting\n",
    "    sample = gamma * sample + delta\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1dffd7-820a-41a0-a240-7f3bd2dec552",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = generation(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c78702-939e-4b0b-9602-b2db6db09944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_ker(u=0, y=0, epsilon=1):\n",
    "    \"\"\"gaussian kernel for weights\n",
    "    \n",
    "    Parameters\n",
    "    -------------------\n",
    "    y : float, or array-like\n",
    "    the point we have, the output\n",
    "\n",
    "    u : float, or array-like\n",
    "    the point from which we want to calculate a weight\n",
    "\n",
    "    epsilon : int, float\n",
    "    the scale parameter for which we want to compute the kernel\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    w = (1/np.sqrt(2*np.pi*(epsilon**2)))*np.exp(-(np.abs((u-y)))**2/(2*(epsilon**2)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d10054d-233d-4e99-8f04-3f9b2443bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zolotarev_transfo(sample, xi=0.25):\n",
    "    \"\"\"function to use for the estimation based on the zolotarev transformation\n",
    "\n",
    "    Parameters\n",
    "    --------------------------\n",
    "    Sample : array-like\n",
    "    Sample to do the transformation on\n",
    "\n",
    "    xi : int, float\n",
    "    The constant used in the transformation\n",
    "    --------------------------\n",
    "    \"\"\"\n",
    "    if xi<=0 or xi>1/2 :\n",
    "        raise ValueError('Xi must be between 0 and 1/2')\n",
    "    taille = len(sample)\n",
    "    Z = []\n",
    "    for i in range(int(taille/3)):\n",
    "        transfo = sample[3*i-2] - xi*sample[3*i-1] - (1 - xi)*sample[3*i]\n",
    "        Z.append(transfo)\n",
    "    V = []\n",
    "    U = []\n",
    "    for i in range(len(Z)):\n",
    "        V.append(np.log(np.abs(Z[i])))\n",
    "        U.append(np.sign(sample[i]))\n",
    "    V = np.array(V)\n",
    "    U = np.array(U)\n",
    "    S_U_squared = (np.std(U))**2\n",
    "    S_V_squared = (np.std(V))**2\n",
    "    nu_tilde = (6/(np.pi)**2)*S_V_squared - (3/2)*S_U_squared + 1\n",
    "    etha_hat = np.mean(U)\n",
    "    tau_hat = np.mean(V)\n",
    "    nu_hat = 0\n",
    "    if nu_tilde > ((1+np.abs(etha_hat))**2)/4:\n",
    "        nu_hat = nu_tilde\n",
    "    else:\n",
    "        nu_hat = ((1+np.abs(etha_hat))**2)/4\n",
    "    delta_hat = np.mean(sample)\n",
    "    S_2 = np.array((nu_hat, etha_hat, tau_hat, delta_hat))\n",
    "    return S_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169a7284-5f32-436c-baba-adc022a66d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "zolo_y = np.zeros((1000, 4))\n",
    "\n",
    "for i in range(1000):    \n",
    "    y = generation(1000)\n",
    "    zolo_y[i] = zolotarev_transfo(sample=y)\n",
    "\n",
    "varcov = np.cov(m=zolo_y, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3420527-05b1-4eb7-92b5-e326a5c58726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_lf(epsilon_t, sample=default, N=1000, alpha=1.7, beta=0.9, gamma=10, delta=10, possession=False):\n",
    "    \"\"\"function to have the likelihood free density given in the article\n",
    "\n",
    "    Parameters\n",
    "    -----------------\n",
    "    N : int\n",
    "    number of priors we want to generate\n",
    "        \n",
    "    alpha, beta, gamma, delta : int, float\n",
    "    the parameters with which we want to compute the true data if we don't already have it\n",
    "\n",
    "\n",
    "    sample : array-like\n",
    "    the data we observe\n",
    "\n",
    "    summary_statistic : array-like\n",
    "    summary statistic used to make tests on the distance between two datasets\n",
    "\n",
    "    epsilon_t : int, float\n",
    "    scale parameter, determines \n",
    "\n",
    "    Possession : boolean\n",
    "    by default, set to false, to determine if we want to generate the data or if we already have it\n",
    "\n",
    "    method : str\n",
    "    the method with which we would compute the summary statistics\n",
    "    -------------------\n",
    "    \"\"\"\n",
    "    if possession == False :\n",
    "        data = generation(n=1000, alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "    else :\n",
    "        data = sample\n",
    "    #set the priors like in the paper\n",
    "    prior_alpha = np.random.uniform(1.1, 2., size=N)\n",
    "    prior_beta = np.random.uniform(-1., 1, size=N)\n",
    "    prior_gamma = np.random.uniform(0., 300., size=N)\n",
    "    prior_delta = np.random.uniform(-300., 300., size=N)\n",
    "    prior_gen = np.vstack((prior_alpha,prior_beta,prior_gamma, prior_delta))\n",
    "    prior_gen = np.transpose(prior_gen)\n",
    "    true_param = zolotarev_transfo(sample=data)\n",
    "\n",
    "    \n",
    "    \n",
    "    proposed_param = np.zeros((N,4))\n",
    "    for i in range(N):\n",
    "        proposed_data = generation(n=N, alpha=prior_gen[i,0], beta=prior_gen[i,1],\n",
    "                                  gamma=prior_gen[i,2], delta=prior_gen[i,3])\n",
    "        proposed_param[i] = zolotarev_transfo(sample=proposed_data)\n",
    "\n",
    "    diff = np.zeros((N,4))   \n",
    "    for i in range(N):\n",
    "        diff[i] = proposed_param[i]-np.random.multivariate_normal(mean=true_param, cov=varcov, size=1)\n",
    "    kernel_applied = gaussian_ker(u=diff, y=0, epsilon=epsilon_t)/epsilon_t\n",
    "\n",
    "    \n",
    "    pi_lf_output = np.zeros((N, 4))\n",
    "    for i in range(N):\n",
    "        pi_lf_output[i] = prior_gen[i]*kernel_applied[i]\n",
    "    \n",
    "    return pi_lf_output, kernel_applied\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c9732e7-15c7-4d19-bf8e-4e5636be5516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_1 = pi_lf(epsilon_t=0.5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bec5b30a-30c4-4370-9bc8-ae681edcc4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5729399518081304"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83675366-c741-4769-9297-e92825c4af78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08955340137574169"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_1[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c473fe0-a2cc-4221-b8cc-76658225be9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418596810264145"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_1[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6123142e-9b04-435e-a2f7-8cb9f18a3567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09150643007470527"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_1[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf230b-869f-42b2-8c8d-40b7a08b9219",
   "metadata": {},
   "source": [
    "# ABC accept reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2750cb27-de32-4046-bae0-a994a914e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees = generation(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "379aa06f-f928-4a40-96cf-c95356b9df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prior = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22c59c89-2d91-4165-9c3e-de9963eaabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_alpha_ar = np.random.uniform(1.1, 2., size=nb_prior)\n",
    "prior_beta_ar = np.random.uniform(-1., 1, size=nb_prior)\n",
    "prior_gamma_ar = np.random.uniform(0., 300., size=nb_prior)\n",
    "prior_delta_ar = np.random.uniform(-300., 300., size=nb_prior)\n",
    "prior_gen_ar = np.vstack((prior_alpha_ar,prior_beta_ar,prior_gamma_ar, prior_delta_ar))\n",
    "prior_gen_ar = np.transpose(prior_gen_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f094a7-9a36-4de7-893f-81a029519901",
   "metadata": {},
   "outputs": [],
   "source": [
    "zolo_proposal = np.zeros((nb_prior, 4))\n",
    "for i in range(nb_prior):\n",
    "    proposal = generation(n=1000, [alpha, beta, gamma, delta] = [prior_gen_ar[i,0], prior_gen_ar[i,1],\n",
    "                                                                 prior_gen_ar[i,2],prior_gen_ar[i,3]]\n",
    "    zolo_proposal[i] = zolotarev_transfo(sample=proposal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e74eb-cf7c-4430-af0e-f51e52df9c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
