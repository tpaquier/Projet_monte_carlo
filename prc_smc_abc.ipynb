{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbda31ac-c884-4056-913a-6695215b34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a2cbc9-5244-47d3-adaf-4e7c727392e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_theta = 1/3240.0\n",
    "varcov_lambda = np.array(([0.25,0,0,0],[0,0.25,0,0],\n",
    "                          [0,0,1,0], [0,0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc08662f-f955-4adf-9273-bb238d42d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prior = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4abdcb91-28c1-4722-8dda-67d5d6e9b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale parameters\n",
    "#epsilon_t\n",
    "\n",
    "mille = np.linspace(start=100, stop=1000, endpoint=True, num=10)[::-1]\n",
    "cent = np.linspace(start=10, stop=100, endpoint=False, num=90)[::-1]\n",
    "dix = np.linspace(start=5, stop=10, endpoint=False, num=10)[::-1]\n",
    "cinq = np.linspace(start=3, stop=5, endpoint=False, num=40)[::-1]\n",
    "trois = np.linspace(start=0, stop=3, endpoint=False, num=300)\n",
    "trois = np.delete(arr=trois, obj=0)\n",
    "trois = trois[::-1]\n",
    "\n",
    "scale_param = np.concatenate((mille, cent, dix, cinq, trois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb02cea-1d52-40eb-8ac3-b4e5c58c83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_alpha = np.random.uniform(1.1, 2., size=1000)\n",
    "prior_beta = np.random.uniform(-1., 1, size=1000)\n",
    "prior_gamma = np.random.uniform(0., 30., size=1000)\n",
    "prior_delta = np.random.uniform(-30., 30., size=1000)\n",
    "prior_gen = np.vstack((prior_alpha,prior_beta,prior_gamma, prior_delta))\n",
    "prior_gen = np.transpose(prior_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d98d2b-3e48-479b-9d7c-d76adcd655ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(n, alpha=1.7, beta=0.9, gamma=10, delta=10):\n",
    "    # Initialize samples array with zeros\n",
    "    sample = np.zeros(n)\n",
    "    \n",
    "    # Constants that do not depend on the sample index and thus can be computed once\n",
    "    if alpha != 1:\n",
    "        S_alpha_beta = (1 + beta ** 2 * np.tan(np.pi * alpha / 2) ** 2) ** (1 / (2 * alpha))\n",
    "        B_alpha_beta = (1 / alpha) * np.arctan(beta * np.tan(np.pi * alpha / 2))\n",
    "\n",
    "    for i in range(n):\n",
    "        U = np.random.uniform(-np.pi/2, np.pi/2)\n",
    "        W = -np.log(1 - np.random.uniform(0,1))\n",
    "        \n",
    "        # Handle the case alpha = 1 separately\n",
    "        if alpha != 1:\n",
    "            part1 = np.sin(alpha * (U + B_alpha_beta)) / (np.cos(U) ** (1 / alpha))\n",
    "            part2 = (np.cos(U - alpha * (U + B_alpha_beta)) / W) ** ((1 - alpha) / alpha)\n",
    "            sample[i] = S_alpha_beta * part1 * part2\n",
    "        else:\n",
    "            sample[i] = (2 / np.pi) * ((np.pi / 2 + beta * U) * np.tan(U) - beta * np.log((np.pi / 2 * W * np.cos(U))/(np.pi+beta*U)))\n",
    "\n",
    "    # Apply scaling and location shifting\n",
    "    sample = gamma * sample + delta\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88d1b91-9c39-49c8-972e-366bdf5254c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_ker(u=0, y=0, epsilon=1):\n",
    "    \"\"\"gaussian kernel for weights\n",
    "    \n",
    "    Parameters\n",
    "    -------------------\n",
    "    y : float, or array-like\n",
    "    the point we have, the output\n",
    "\n",
    "    u : float, or array-like\n",
    "    the point from which we want to calculate a weight\n",
    "\n",
    "    epsilon : int, float\n",
    "    the scale parameter for which we want to compute the kernel\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    w = (1/np.sqrt(2*np.pi*(epsilon**2)))*np.exp(-(np.abs((u-y)))**2/(2*(epsilon**2)))/epsilon\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b79ce4-2ad1-49f8-964a-00fe8eedf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zolotarev_transfo(sample, xi=0.25):\n",
    "    \"\"\"function to use for the estimation based on the zolotarev transformation\n",
    "\n",
    "    Parameters\n",
    "    --------------------------\n",
    "    Sample : array-like\n",
    "    Sample to do the transformation on\n",
    "\n",
    "    xi : int, float\n",
    "    The constant used in the transformation\n",
    "    --------------------------\n",
    "    \"\"\"\n",
    "    if xi<=0 or xi>1/2 :\n",
    "        raise ValueError('Xi must be between 0 and 1/2')\n",
    "    taille = len(sample)\n",
    "    Z = []\n",
    "    for i in range(1,int(taille/3)+1):\n",
    "        transfo = sample[3*i-3] - xi*sample[3*i-2] - (1 - xi)*sample[3*i-1]\n",
    "        Z.append(transfo)\n",
    "    V = []\n",
    "    U = []\n",
    "    for i in range(len(Z)):\n",
    "        V.append(np.log(np.abs(Z[i])))\n",
    "        U.append(np.sign(sample[i]))\n",
    "    V = np.array(V)\n",
    "    U = np.array(U)\n",
    "    S_U_squared = (np.std(U))**2\n",
    "    S_V_squared = (np.std(V))**2\n",
    "    nu_tilde = (6/(np.pi)**2)*S_V_squared - (3/2)*S_U_squared + 1\n",
    "    etha_hat = np.mean(U)\n",
    "    tau_hat = np.mean(V)\n",
    "    nu_hat = 0\n",
    "    if nu_tilde > ((1+np.abs(etha_hat))**2)/4:\n",
    "        nu_hat = nu_tilde\n",
    "    else:\n",
    "        nu_hat = ((1+np.abs(etha_hat))**2)/4\n",
    "    delta_hat = np.mean(sample)\n",
    "    S_2 = np.array((nu_hat, etha_hat, tau_hat, delta_hat))\n",
    "    return S_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe8f3ce3-ae0d-4c89-ba1a-d96b0f72858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = generation(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae0c626-4527-44f3-a5ab-0fa5979eae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_integrand(u, epsilon_t):\n",
    "    return np.exp(-u**2 / (2 * epsilon_t**2)) / (np.sqrt(2 * np.pi) * epsilon_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa2e390-c46f-4d21-9902-18b0854a4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_lf(epsilon_t, sample=default, alpha=1.7, beta=0.9, gamma=10, delta=10, possession=False):\n",
    "    \"\"\"function to have the likelihood free density given in the article, the data we create if there is\n",
    "    no data provided is based on the parameters of 'generation', so for any comparaison between the values of theta,\n",
    "    those are the parameters to change\n",
    "\n",
    "    Parameters\n",
    "    -----------------\n",
    "    N : int\n",
    "    number of priors we want to generate\n",
    "        \n",
    "    alpha, beta, gamma, delta : int, float\n",
    "    the parameters with which we want to compute the true data if we don't already have it\n",
    "\n",
    "\n",
    "    sample : array-like\n",
    "    the data we observe\n",
    "\n",
    "    summary_statistic : array-like\n",
    "    summary statistic used to make tests on the distance between two datasets\n",
    "\n",
    "    epsilon_t : int, float\n",
    "    scale parameter, determines \n",
    "\n",
    "    Possession : boolean\n",
    "    by default, set to false, to determine if we want to generate the data or if we already have it\n",
    "\n",
    "    method : str\n",
    "    the method with which we would compute the summary statistics\n",
    "    -------------------\n",
    "    \"\"\"\n",
    "    if possession == False :\n",
    "        data = generation(n=1000)\n",
    "    else :\n",
    "        data = sample\n",
    "    true_param = zolotarev_transfo(sample=data)\n",
    "    proposal = generation(n=1000, alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "    zolo_proposal = zolotarev_transfo(sample=proposal)\n",
    "    weight = gaussian_ker(u=np.linalg.norm(true_param-zolo_proposal), epsilon=epsilon_t)\n",
    "    pi_lf = weight*pi_theta\n",
    "\n",
    "\n",
    "    normalization_constant, _ = quad(custom_integrand, 0, np.inf, args=(epsilon_t,))\n",
    "\n",
    "\n",
    "    pi_lf = pi_lf / normalization_constant\n",
    "\n",
    "    return pi_lf\n",
    "    \n",
    "    return pi_lf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9743e2-f4ac-47f2-8f52-53e3505cc79d",
   "metadata": {},
   "source": [
    "weight_gen[i] = pi_lf(epsilon_t=periode_t, theta_i, sample=y)/mutation_density(theta_i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29053631-5d75-437a-91b8-b993085e4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_creation(theta_t_1):\n",
    "    \"\"\"a function to sample a theta_t^(i) as in the paper, according to the distribution of the mutation\n",
    "    kernel\n",
    "\n",
    "    Parameters\n",
    "    -------------------------\n",
    "    theta_t_1 : array,\n",
    "    the parameter at step t - 1\n",
    "    --------------------------\n",
    "    \"\"\"\n",
    "    weighted_random = np.zeros((nb_prior,4))\n",
    "    for i in range(nb_prior):\n",
    "        weighted_random[i] = weight_gen[i]*multivariate_normal.rvs(mean=theta_t_1, cov=varcov_lambda, size=1)\n",
    "    mt_theta = np.sum(a=weighted_random, axis=0)\n",
    "    return mt_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb10ad10-3880-4e76-aec7-220bb71b8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_density(theta_t, theta_t_1):\n",
    "    \"\"\"function that evaluates the pdf of the kernel for a given theta\n",
    "\n",
    "    Parameters\n",
    "    ----------------------\n",
    "    theta_t : 1-D array, \n",
    "    the parameter of which we will estimate the probability density at step t\n",
    "\n",
    "    theta_t_1 : array, \n",
    "    the parameter at a step before\n",
    "    ----------------------\n",
    "    \"\"\"\n",
    "    weighted_estimated = np.zeros(nb_prior)\n",
    "    for i in range(nb_prior):\n",
    "        weighted_estimated[i] = weight_gen[i]*multivariate_normal.pdf(theta_t, mean=theta_t_1,\n",
    "                                                                      cov=varcov_lambda)\n",
    "    mt_theta = np.sum(a=weighted_estimated, axis=0)\n",
    "    return mt_theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba9404f3-3b45-4398-aee9-04520d1721b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_gen = np.zeros((1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eed6ef3-c169-4f1b-8357-8155bc61d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(prior_gen=prior_gen, weight_gen=weight_gen, N=1000):\n",
    "    \"\"\"Resample N particles (rows) from 'prior_gen' matrix based on weights in 'weight_gen'.\n",
    "    \n",
    "    Parameters\n",
    "    ------------------------\n",
    "    prior_gen : 1-D or 2-D array,\n",
    "    matrix of prior particles where each row is a particle\n",
    "\n",
    "    weight_gen : 1-D or 2-D array \n",
    "    vector of weights corresponding to particles\n",
    "    \n",
    "    N : int,\n",
    "    number of particles to resample.\n",
    "    -------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    weights = weight_gen / np.sum(weight_gen)\n",
    "    \n",
    "    indices = np.random.choice(prior_gen.shape[0], size=N, replace=True, p=weights)\n",
    "    \n",
    "    resampled_particles = prior_gen[indices, :]\n",
    "    \n",
    "    return resampled_particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66257325-1fd0-4907-92d5-0df62af21bd7",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79ebba09-9a20-4130-911c-4d5139752179",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prior=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7aecece-dea0-4aae-9b7e-a59805c3e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = generation(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dff2821-b140-49db-a765-926eb4159be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_gen = np.zeros((nb_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72512774-f95e-4a52-8a57-491c3a346e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_alpha = np.random.uniform(1.6, 1.7, size=nb_prior)\n",
    "prior_beta = np.random.uniform(0.5, 1, size=nb_prior)\n",
    "prior_gamma = np.random.uniform(9, 11, size=nb_prior)\n",
    "prior_delta = np.random.uniform(9, 11, size=nb_prior)\n",
    "prior_gen = np.vstack((prior_alpha,prior_beta,prior_gamma, prior_delta))\n",
    "prior_gen = np.transpose(prior_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a93d7316-9166-4cc9-a59c-ac114ab1e3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 83.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(nb_prior)):\n",
    "    weight_gen[i] = pi_lf(epsilon_t=scale_param[0], alpha=prior_alpha[i],\n",
    "                          beta=prior_beta[i], gamma=prior_gamma[i],\n",
    "                          delta=prior_delta[i], possession=True, sample=y)/pi_theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69b6334f-9374-402b-912c-d8a5f5d8bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_gen=resample(prior_gen=prior_gen, weight_gen=weight_gen, N=nb_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18dd3812-cfb3-4fc7-af1a-999bb300ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_t = prior_gen\n",
    "prior_t_1 = prior_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2bcbb7a-633c-4306-840b-973f3508a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_gen = np.ones(nb_prior)*1/nb_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3aa7e11a-04cd-43ed-af68-c299242be11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/tmp/ipykernel_2722/3625153862.py:17: RuntimeWarning: invalid value encountered in scalar power\n",
      "  part2 = (np.cos(U - alpha * (U + B_alpha_beta)) / W) ** ((1 - alpha) / alpha)\n",
      "\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.29s/it]\u001b[A/tmp/ipykernel_2722/3086114734.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "  V.append(np.log(np.abs(Z[i])))\n",
      "\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.28s/it]\u001b[A/tmp/ipykernel_2722/3625153862.py:7: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  S_alpha_beta = (1 + beta ** 2 * np.tan(np.pi * alpha / 2) ** 2) ** (1 / (2 * alpha))\n",
      "/tmp/ipykernel_2722/3625153862.py:8: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  B_alpha_beta = (1 / alpha) * np.arctan(beta * np.tan(np.pi * alpha / 2))\n",
      "/tmp/ipykernel_2722/3625153862.py:8: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  B_alpha_beta = (1 / alpha) * np.arctan(beta * np.tan(np.pi * alpha / 2))\n",
      "/tmp/ipykernel_2722/3625153862.py:16: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  part1 = np.sin(alpha * (U + B_alpha_beta)) / (np.cos(U) ** (1 / alpha))\n",
      "/tmp/ipykernel_2722/3625153862.py:17: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  part2 = (np.cos(U - alpha * (U + B_alpha_beta)) / W) ** ((1 - alpha) / alpha)\n",
      "/tmp/ipykernel_2722/1400037538.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = weight_gen / np.sum(weight_gen)\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.81s/it]\n",
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compteur \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[1;32m     25\u001b[0m         weight_gen[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 27\u001b[0m prior_t \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprior_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_prior\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(prior_gen, weight_gen, N)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample N particles (rows) from 'prior_gen' matrix based on weights in 'weight_gen'.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m-------------------------\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m weights \u001b[38;5;241m=\u001b[39m weight_gen \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(weight_gen)\n\u001b[0;32m---> 19\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(prior_gen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39mN, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, p\u001b[38;5;241m=\u001b[39mweights)\n\u001b[1;32m     21\u001b[0m resampled_particles \u001b[38;5;241m=\u001b[39m prior_gen[indices, :]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resampled_particles\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:971\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(10)):\n",
    "    c_t = np.quantile(a=weight_gen, q=0.9) #we set the threshold as in the paper, before\n",
    "    weight_gen = np.ones(nb_prior)*1/nb_prior\n",
    "    prior_t_1 = prior_t\n",
    "    for i in tqdm(range(nb_prior)):\n",
    "        p_i = 0\n",
    "        decision = 0\n",
    "        compteur = 0\n",
    "        while decision != 1 and compteur<100:\n",
    "            theta_proposal = mutation_creation(prior_t_1[i])\n",
    "            weight_gen[i] = pi_lf(possession=True, sample=y, epsilon_t=scale_param[k],\n",
    "                                  alpha=theta_proposal[0], beta=theta_proposal[1],\n",
    "                                  gamma=theta_proposal[2], delta=theta_proposal[2])/mutation_density(theta_t=prior_t[i],\n",
    "                                                                                                     theta_t_1=prior_t_1[i])\n",
    "\n",
    "            p_i = np.min((1,weight_gen[i]/c_t))\n",
    "\n",
    "            if 0 < p_i < 1:\n",
    "                decision = bernoulli.rvs(p_i, size=1)\n",
    "                if decision == 1:\n",
    "                    prior_t[i] = theta_proposal\n",
    "                    weight_gen[i] = weight_gen[i]/p_i\n",
    "            compteur += 1\n",
    "            if compteur == 100:\n",
    "                weight_gen[i] = 0\n",
    "\n",
    "        prior_t = resample(prior_gen=prior_t, weight_gen=weight_gen, N=nb_prior)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a951ea-9c1f-4e31-a396-26209f748bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_param[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad0ce9-a9b5-433f-a4b3-69d9dce883ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
